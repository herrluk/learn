# LEC1

## 单词扫盲

### MapReduce 论文

intermediate	*adj.*居中的，中间的；中等程度的，中级的	*n.*中级水平者，中级学生；中间事物；（化合物）中间体	*v.*充当调解人，斡旋

Scalable 可扩展的；可扩张性；可扩展性；可塑化

crawler 爬虫；爬行器；爬行者

derive	*v.*获得，取得；起源于，来自；提取，衍生（化学物质）

derived	*adj.*导出的；衍生的，派生的	*v.*从……衍生出，源于；（从……中）得到，提取；

derived data	派生数据

inverted index	倒排索引；反向索引；反转索引；概括来说

conspire	*v.*密谋，共谋；共同导致

conspire to obscure the original simple computation 和谋掩盖了原来的简单计算

primitive	*adj.*原始的，远古的；（器物等）粗糙的，简陋的；（人、动物或植物发展）早期的；（行为，思想，情感）本能的，自然的；*n.*（数）基本式，初基；（计算机）图元，原语

primitives present 原始表达

RPC是远程过程调用（Remote Procedure Call）

projective geometry *n.*[数] 射影几何；投影几何学

Slide 幻灯片

tremendous *adj.*巨大的，极大的；极好的，精彩的；令人望而生畏的，可怕的

archive n. 存档材料，档案；档案室 v. 把……存档，把……归档

prompt *v.*促使，导致；鼓励，提示（说话者）；**（计算机上）提示；**（给演员）提词，提白

*adj.*迅速的，立刻的；（人）利索的，敏捷的；及时的，准时的；（商品）即期要送的，即期要付的

*n.*（给演员的）提词；（**计算机屏幕上显示准备接受指令的）提示**； 鼓励，催促；（付款通知单上的）付款期限

*adv.*准时地

tilde  n. 波浪字符，代字号；（数学或逻辑学中的）否定符号

Arithmetic *n.*算术；演算，计算；数据统计 *adj.*算术的

Modulo *prep.*以……为模 *adj.*按模的

parenthesis	*n.*圆括号；插入成分，插入语；插曲，间歇

assignment	*n.*作业，任务；（工作等的）分配，指派；（财产、权利的）转让

statement	*n.*声明，报告；说明，说法，表态；结算单，报表；（某观点的） 表达；（嫌犯或证人向警方提供的） 陈述，证词；（文字）陈述，表述；（乐）（作品主题或旋律的）呈现；**（计算机程序中的）语句**

Assignment statements 赋值语句

 component	*n.*组成部份，成分，部件 	*adj.*组成的，构成的

docstring 三重引号

`>>>` are called **doctests**

back up  *v.*支持，援助；（资料）备份；倒退；裱；堵车

handy  *adj.*有用的，方便的，便于使用的；手巧的，有手艺的；手边的，附近的

Here are a few that will come in handy. 	这里有一些会派上用场的方法。

session	*n.*（某项活动的）一段时间，一场；（议会等的）会议，（法庭的）开庭；学年，上课时间；（酒吧中）演奏会（尤指演奏爱尔兰音乐）；（尤指录音师的）灌录音乐时间；

Notation *n.*（音乐、数学等的）标记系统，成套符号，标记法；注释，评注

Call expression 调用表达式

infix	*v.*把……植入；插入（中缀）；用力插入	*adj.*中缀的	*n.*中缀 	prefix 前缀 suffix 后缀

parenthesis	*n.*圆括号；插入成分，插入语；插曲，间歇

operand	*n.*[计] 操作数；[计] 运算对象	operator 操作符

assignment	*n.*作业，任务；（工作等的）分配，指派；（财产、权利的）转让

assignment statement	[计] 赋值语句



#### 2. Programming Model

invocation *n.*（向神或权威人士的）求助，祈祷；咒语；（仪式或集会开始时的）发言，祷文；（法院对另案的）文件调取；**（计算机）调用，启用**；（法权的）行使

invocate *v.*祈求；援引；引起（等于 invoke）

The computation takes a set of input key/value pairs, and produces a set of output key/value pairs.

该计算模型接受一组键/值对作为输入，输出一组键/值对。

The user of the MapReduce library expresses the computation as two functions: Map and Reduce.

使用MapReduce库的用户需要定义两个函数：Map和Reduce。

Map, written by the user, takes an input pair and produces a set of intermediate key/value pairs.

用户编写的Map函数接受一个输入键/值对，并生成一组中间键/值对。

The MapReduce library groups together all intermediate values associated with the same intermediate key I and passes them to the Reduce function.

MapReduce库将所有与同一中间键I相关联的中间值分组，并将它们传递给Reduce函数。

The Reduce function, also written by the user, accepts an intermediate key I and a set of values for that key.

用户编写的Reduce函数接受一个中间键I和一组该键对应的值。

It merges together these values to form a possibly smaller set of values.

它将这些值合并在一起，形成可能更小的值集合。

Typically just zero or one output value is produced per Reduce invocation.

通常，每次Reduce调用只会产生一个输出值。

The intermediate values are supplied to the user’s reduce function via an iterator.

中间值通过一个迭代器传递给用户的Reduce函数。

This allows us to handle lists of values that are too large to fit in memory.

这样可以处理太大而无法放入内存的值列表。

##### 2.1 Example

考虑在大量文档集合中统计每个单词出现的次数的问题。用户将编写类似以下伪代码的代码：

The map function emits each word plus an associated count of occurrences (just ‘1’ in this simple example).
map函数发出每个单词以及相关的出现次数（在这个简单的例子中只有'1'）。

The reduce function sums together all counts emitted for a particular word.
reduce函数将发出的所有与特定单词相关的计数相加。

In addition, the user writes code to fill in a mapreduce specification object with the names of the input and output files, and optional tuning parameters. The user then invokes the MapReduce function, passing it the specification object.
此外，用户编写代码来填写一个MapReduce规范对象，其中包含输入和输出文件的名称以及可选的调整参数。然后，用户调用MapReduce函数，将规范对象传递给它。

The user’s code is linked together with the MapReduce library (implemented in C++).
用户的代码与MapReduce库（用C++实现）链接在一起。

Appendix A contains the full program text for this example.
附录A包含了这个例子的完整程序文本。

##### 2.2 Types

pseudo-code 伪代码 Pseudo是希腊语中“假的，虚假的”的意思。在英语中，它通常用来表示“假的，虚假的，伪造的”的意思

Even though the previous *pseudo-code* is written in terms of string inputs and outputs, conceptually the map and reduce functions supplied by the user have associated types:
尽管前面的伪代码是针对字符串输入和输出编写的，但用户提供的map和reduce函数在概念上具有关联类型：

```
map(k1, v1) → list(k2, v2)
reduce(k2, list(v2)) → list(v2)
```

即，输入键和值来自不同的域，而输出键和值则来自不同的域。此外，中间键和值与输出键和值来自相同的域。

Our C++ implementation passes strings to and from the user-defined functions and leaves it to the user code to convert between strings and appropriate types.
我们的C++实现将字符串传递给用户定义的函数，并让用户代码在字符串和适当类型之间进行转换。

这段文字解释了用户提供的map和reduce函数的类型，以及C++实现如何处理这些函数的输入和输出。虽然用户提供的函数的输入和输出是字符串类型的，但是这些函数实际上有关联的类型。同时，C++实现将字符串传递给用户定义的函数，并让用户代码来处理类型转换。

##### 2.3 More Examples

Here are a few simple examples of interesting programs that can be easily expressed as MapReduce computations.

这里有几个简单的示例，这些程序可以轻松地表示为MapReduce计算。

Distributed Grep: The map function emits a line if it matches a supplied pattern. The reduce function is an identity function that just copies the supplied intermediate data to the output.

分布式grep：如果一行与提供的模式匹配，map函数将发出该行。reduce函数是一个身份函数，仅将提供的中间数据复制到输出。

Count of URL Access Frequency: The map function processes logs of web page requests and outputs <URL,1>.The reduce function adds together all values for the same URL and emits a <URL, total count> pair.

URL访问频率计数：map函数处理网页请求的日志并输出h URL, 1i。reduce函数将同一URL的所有值相加，并发出< URL，总计数>对。

Reverse Web-Link Graph: The map function outputs < target, source> pairs for each link to a target URL found in a page named source. The reduce function concatenates the list of all source URLs associated with a given target URL and emits the pair: < target, list(source)>

反向网页链接图：map函数为每个指向名为source的页面中找到的目标URL链接输出< target, source>对。reduce函数将与给定目标URL相关联的所有源URL的列表连接起来，并发出对：< target, list(source)>。

Term-Vector per Host: A term vector summarizes the most important words that occur in a document or a set of documents as a list of < word, frequency > pairs. The map function emits a <hostname, term vector> pair for each input document (where the hostname is extracted from the URL of the document). The reduce function is passed all per-document term vectors for a given host. It adds these term vectors together, throwing away infrequent terms, and then emits a final <hostname, term vector> pair.

每个主机的Term-Vector：术语向量总结文档或一组文档中出现的最重要的单词，作为< word, frequency >对的列表。map函数为每个输入文档（其中主机名从文档的URL中提取）发出<hostname, term vector>对。reduce函数传递给给定主机的所有每个文档的术语向量。它将这些术语向量相加，丢弃不常见的术语，然后发出最终的<hostname, term vector>对。

#### 3. Implement

Many different implementations of the MapReduce interface are possible. The right choice depends on the
environment. For example, one implementation may be suitable for a small shared-memory machine, another for a large NUMA multi-processor, and yet another for an even larger collection of networked machines.

MapReduce接口有很多不同的实现方式，正确的选择取决于环境。例如，一种实现方式可能适用于小型共享内存机器，另一种则适用于大型NUMA多处理器，还有一种则适用于更大的网络机器集合。

This section describes an implementation targeted to the computing environment in wide use at Google: large clusters of commodity PCs connected together with switched Ethernet [4]. In our environment:

本节介绍了一种针对谷歌广泛使用的计算环境的实现：由连接在一起的廉价PC集群，采用交换式以太网[4]。在我们的环境中：

- Machines are typically dual-processor x86 processors running Linux, with 2-4 GB of memory per machine.
- Commodity networking hardware is used – typically either 100 megabits/second or 1 gigabit/second at the machine level, but averaging considerably less in overall bisection bandwidth.
- A cluster consists of hundreds or thousands of machines, and therefore machine failures are common.
- Storage is provided by inexpensive IDE disks attached directly to individual machines. A distributed file system [8] developed in-house is used to manage the data stored on these disks. The file system uses replication to provide availability and reliability on top of unreliable hardware.
- Users submit jobs to a scheduling system. Each job consists of a set of tasks, and is mapped by the scheduler to a set of available machines within a cluster.
- 机器通常是运行Linux的双处理器x86处理器，每台机器具有2-4GB的内存。
- 使用廉价的网络硬件-通常是每台机器100兆位/秒或1千兆位/秒，但总体的双向带宽要低得多。
- 集群由数百或数千台机器组成，因此机器故障很常见。
- 存储由直接连接到各个机器的廉价IDE磁盘提供。使用内部开发的分布式文件系统[8]来管理存储在这些磁盘上的数据。文件系统使用复制来提供可靠性和可用性，以弥补不可靠硬件的缺陷。
- 用户将作业提交到调度系统。每个作业由一组任务组成，并由调度器映射到集群内的一组可用机器。

## 实验



```
go build -race -buildmode=plugin ../mrapps/wc.go
```

这是一个使用 Go 语言编写 MapReduce 程序的命令。其中 `-race` 和 `-buildmode=plugin` 都是编译参数。

`-race` 参数表示使用 Go 语言内置的竞态检测工具，检测程序中的并发问题，包括数据竞争和线程死锁等问题。在编译时添加 `-race` 参数会使编译器在生成二进制文件时插入一些额外的代码，用于检测和记录程序中的并发操作，然后在运行时对这些操作进行检测和报告。

`-buildmode=plugin` 参数表示编译成一个插件文件，用于在 MapReduce 框架中加载和执行。在编译时添加 `-buildmode=plugin` 参数会告诉编译器生成一个动态链接库，包含了 Map 和 Reduce 函数的实现，然后可以在 MapReduce 框架中通过加载插件文件来调用这些函数。

# LEC2

## 单词扫盲

semantics *n.*[语] 语义学；语义论  	semantic *adj.*语义的；语义学的

## 课程

### 投票

##### 投票程序 1

```go
func main() {
	rand.Seed(time.Now().UnixNano())

	count := 0
	finished := 0

	for i := 0; i < 10; i++ {
		go func() {
			vote := requestVote()
			if vote {
				count++
			}
			finished++
		}()
	}

	for count < 5 && finished != 10 {
		// wait
	}
	if count >= 5 {
		println("received 5+ votes!")
	} else {
		println("lost")
	}
}

func requestVote() bool {
	time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)
	return rand.Int() % 2 == 0
}

```

这段 Go 代码中实现了一个简单的多个 goroutine 投票的场景，其中的 `requestVote` 函数用于模拟一个投票操作，返回一个 bool 值表示是否投票成功，而主函数 `main` 中则启动了 10 个 goroutine 同时进行投票操作，并统计投票成功的次数。

具体来说，这段代码的执行过程如下：

1. 使用 `time.Now().UnixNano()` 作为随机数生成器 `rand` 的种子，确保每次运行程序时生成的随机数序列都不同。
2. 初始化 `count` 和 `finished` 变量，分别用于统计投票成功的次数和已完成投票的 goroutine 数量。
3. 启动 10 个 goroutine，每个 goroutine 都会执行 `requestVote` 函数模拟一次投票操作，并根据投票结果更新 `count` 和 `finished` 变量。
4. 循环等待，直到至少有 5 个 goroutine 投票成功或者所有投票操作都已完成。这里使用了一个阻塞式的循环等待，代码中的注释 `// wait` 表示等待操作的具体实现。
5. 如果投票成功的次数 `count` 大于等于 5，则打印输出 "received 5+ votes!"；否则，打印输出 "lost"。
6. `requestVote` 函数会随机等待一段时间（0-100ms），然后返回一个随机的 bool 值表示投票是否成功。其中，`rand.Intn(100)` 用于生成 0-99 之间的随机整数，`time.Duration` 用于将整数转换为 Duration 类型，从而指定等待的时间长度。



**Q1：这段代码有什么错误？**

> 在给定的代码中，**并发的 goroutine 可能会同时访问共享变量 `count` 和 `finished`，从而导致竞态条件（race condition）的出现，使得投票的统计结果不准确**。具体来说，如果多个 goroutine 同时对 `count` 或 `finished` 变量进行写操作，就可能导致其中一些操作被覆盖或者丢失，从而影响统计结果的正确性。
>
> 这个问题可以通过使用 Go 语言提供的同步原语来解决，例如使用互斥锁（Mutex）或者原子操作（Atomic Operations）来保证对共享变量的访问是互斥的。具体来说，可以在 `main` 函数中定义一个互斥锁 `mutex`，然后在对 `count` 和 `finished` 变量的访问操作前加上 `mutex.Lock()`，在操作完成后加上 `mutex.Unlock()`，以确保每个操作都是原子的，不会被其他 goroutine 干扰。



##### 投票程序 2

```
func main() {
	rand.Seed(time.Now().UnixNano())

	count := 0
	finished := 0
	var mu sync.Mutex

	for i := 0; i < 10; i++ {
		go func() {
			vote := requestVote()
			mu.Lock()
			defer mu.Unlock()
			if vote {
				count++
			}
			finished++
		}()
	}

	for {
		mu.Lock()

		if count >= 5 || finished == 10 {
			break
		}
		mu.Unlock()
	}
	if count >= 5 {
		println("received 5+ votes!")
	} else {
		println("lost")
	}
	mu.Unlock()
}

func requestVote() bool {
	time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)
	return rand.Int()%2 == 0
}

```

在 `main` 函数的第二个 for 循环中，使用 `mu.Lock()` 获取了互斥锁，然后判断是否已经收到了 5 个及以上的赞成票，或者已经完成了所有的投票请求。如果满足条件，则使用 `break` 退出循环。如果不满足条件，则使用 `mu.Unlock()` 释放互斥锁，进行下一次循环。

最后，在 if-else 语句中，根据收到的赞成票数是否大于等于 5 来输出相应的提示信息。需要注意的是，在输出之前，需要再次使用 `mu.Lock()` 获取互斥锁，避免多个 goroutine 同时访问变量 `count` 和 `finished`。

在这段 Go 代码中，`mu.Lock()` 和 `mu.Unlock()` 的作用是保证多个 goroutine 对共享变量 `count` 和 `finished` 的访问是互斥的，从而避免出现竞态条件等问题。

具体来说，当一个 goroutine 需要访问共享变量时，它需要先获取互斥锁，即执行 `mu.Lock()`，如果此时互斥锁已经被其他 goroutine 占用，则当前 goroutine 将会被阻塞，直到互斥锁被释放。一旦获取到互斥锁，该 goroutine 就可以安全地访问共享变量，执行相应的操作，例如对 `count` 和 `finished` 进行加减操作等。在操作完成之后，该 goroutine 需要释放互斥锁，即执行 `mu.Unlock()`，以便其他 goroutine 可以获取互斥锁并访问共享变量。



第二个 for 循环中的 `mu.Lock()` 和 `mu.Unlock()` 的作用是保证多个 goroutine 对共享变量 `count` 和 `finished` 的访问是互斥的，同时也用来实现等待条件的同步机制。

具体来说，在第二个 for 循环中，多个 goroutine 都需要访问共享变量 `count` 和 `finished`，并根据它们的值来进行判断，从而决定是否需要退出循环。由于这些操作都是对共享变量的读取操作，因此需要使用互斥锁来保证它们的互斥性，避免出现竞态条件等问题。

在第二个 for 循环中，当一个 goroutine 需要访问共享变量时，它需要先获取互斥锁，即执行 `mu.Lock()`，如果此时互斥锁已经被其他 goroutine 占用，则当前 goroutine 将会被阻塞，直到互斥锁被释放。一旦获取到互斥锁，该 goroutine 就可以安全地访问共享变量，执行相应的操作，例如对 `count` 和 `finished` 进行读取操作等。在操作完成之后，该 goroutine 需要释放互斥锁，即执行 `mu.Unlock()`，以便其他 goroutine 可以获取互斥锁并访问共享变量。

##### 投票程序 3

```
func main() {
	rand.Seed(time.Now().UnixNano())

	count := 0
	finished := 0
	var mu sync.Mutex

	for i := 0; i < 10; i++ {
		go func() {
			vote := requestVote()
			mu.Lock()
			defer mu.Unlock()
			if vote {
				count++
			}
			finished++
		}()
	}

	for {
		mu.Lock()
		if count >= 5 || finished == 10 {
			break
		}
		mu.Unlock()
		time.Sleep(50 * time.Millisecond)
	}
	if count >= 5 {
		println("received 5+ votes!")
	} else {
		println("lost")
	}
	mu.Unlock()
}

func requestVote() bool {
	time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)
	return rand.Int() % 2 == 0
}

```

和之前的代码相比，这里加入了一个 `time.Sleep()` 函数，使得在第二个 for 循环中，每次获取互斥锁之前都会等待 50 毫秒。

具体来说，代码中的 `main` 函数启动了 10 个 goroutine，每个 goroutine 执行 `requestVote` 函数请求一次投票，并将投票结果存储到变量 `count` 和 `finished` 中。其中，变量 `count` 表示收到的赞成票数，变量 `finished` 表示已经完成投票的 goroutine 数量。

在 for 循环中，使用 `go func()` 启动了 10 个 goroutine，每个 goroutine 执行 `requestVote()` 函数请求一次投票，并将投票结果存储到变量 `count` 和 `finished` 中。

在第二个 for 循环中，使用 `mu.Lock()` 获取了互斥锁，然后判断是否已经收到了 5 个及以上的赞成票，或者已经完成了所有的投票请求。如果满足其中任意一个条件，则使用 `break` 退出循环；否则，使用 `mu.Unlock()` 释放互斥锁，并使用 `time.Sleep()` 函数等待 50 毫秒，然后继续循环。

在第二个 for 循环之后，根据收到的赞成票数判断是否获胜，并输出相应的结果。

在这个例子中，使用互斥锁的目的是为了保证对共享变量的访问是同步的，避免出现竞态条件等问题。同时，使用 `time.Sleep()` 函数等待一段时间，可以模拟网络延迟等情况，从而更好地验证代码的正确性。

##### 投票程序 4

```go
func main() {
	// 初始化随机数生成器
	rand.Seed(time.Now().UnixNano())

	// 定义变量，分别表示收到的赞成票数和已经完成投票的 goroutine 数量
	count := 0
	finished := 0

	// 创建互斥锁和条件变量
	var mu sync.Mutex
	cond := sync.NewCond(&mu)

	// 启动 10 个 goroutine，每个 goroutine 请求一次投票
	for i := 0; i < 10; i++ {
		go func() {
			vote := requestVote() // 请求投票
			mu.Lock()            // 加锁
			defer mu.Unlock()    // 解锁
			if vote {
				count++ // 如果收到赞成票，则将 count 变量加 1
			}
			finished++     // 已经完成投票的 goroutine 数量加 1
			cond.Broadcast() // 通知条件变量
		}()
	}

	mu.Lock() // 加锁
	// 如果收到的赞成票数小于 5，并且没有完成所有投票，则等待条件变量的通知
	for count < 5 && finished != 10 {
		cond.Wait() // 等待条件变量
	}
	if count >= 5 {
		println("received 5+ votes!") // 如果收到的赞成票数大于等于 5，则输出结果
	} else {
		println("lost") // 否则，输出结果
	}
	mu.Unlock() // 解锁
}

func requestVote() bool {
	time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) // 模拟一些耗时的操作
	return rand.Int()%2 == 0 // 模拟随机的投票结果
}
```

这段 Go 代码和之前的代码相比，使用了 sync.Cond 类型来实现了条件变量的等待和通知。

在 for 循环中，使用 `go func()` 启动了 10 个 goroutine，每个 goroutine 执行 `requestVote()` 函数请求一次投票，并将投票结果存储到变量 `count` 和 `finished` 中。

在第一个 for 循环之后，使用 `mu.Lock()` 获取了互斥锁，并进入了一个 for 循环。在这个循环中，使用 `cond.Wait()` 等待条件变量 `cond` 的通知。具体来说，通过 `cond.Wait()` 函数，当前 goroutine 会释放互斥锁 `mu`，然后等待条件变量 `cond` 的通知。一旦收到通知，该 goroutine 将会重新获取互斥锁 `mu`，然后继续执行后面的代码。

在第一个 for 循环中，每个 goroutine 在完成投票之后，都会调用 `cond.Broadcast()` 函数通知条件变量 `cond`。

在这个例子中，**使用条件变量的目的是为了避免在第二个 for 循环中不停地获取和释放互斥锁**，从而减少了不必要的 CPU 开销。同时，使用条件变量也可以实现线程之间的同步和通信，更加灵活和高效。

##### 投票程序 5

```
func main() {
	rand.Seed(time.Now().UnixNano())

	count := 0
	finished := 0
	ch := make(chan bool)
	for i := 0; i < 10; i++ {
		go func() {
			ch <- requestVote()
		}()
	}
	for count < 5 && finished < 10 {
		v := <-ch
		if v {
			count += 1
		}
		finished += 1
	}
	if count >= 5 {
		println("received 5+ votes!")

	} else {
		println("lost")
	}
}

func requestVote() bool {
	time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)
	return rand.Int()%2 == 0
}

```

这段 Go 代码实现了一个简单的投票应用程序，使用了 channel 来协调多个 goroutine 之间的同步和通信。

在 main 函数中，首先使用 rand.Seed 函数初始化随机数生成器。然后，定义了变量 count 和 finished，分别表示收到的赞成票数和已经完成投票的 goroutine 数量。

接下来，使用 make 函数创建了一个 bool 类型的 channel ch。在 for 循环中，使用 go func() 启动了 10 个 goroutine，每个 goroutine 执行 requestVote() 函数请求一次投票，并将投票结果发送到 channel ch 中。

在第二个 for 循环中，使用 <-ch 语句从 channel ch 中接收投票结果，并将结果存储到变量 v 中。如果 v 为 true，则将 count 变量加 1；否则，不做任何操作。同时，将 finished 变量加 1。

在第二个 for 循环中，只有当收到的赞成票数 count 小于 5，并且已经完成投票的 goroutine 数量 finished 小于 10 时，才会继续循环。一旦收到足够的投票结果，该循环就会退出。

最后，根据 count 的值，输出相应的结果。

在 requestVote() 函数中，使用 time.Sleep 函数模拟了一些耗时的操作，并通过 rand.Int()%2 == 0 语句模拟了随机的投票结果。如果投票结果为 true，则表示收到了赞成票。

总之，这段 Go 代码使用了 channel，实现了多个 goroutine 之间的协作和通信，从而实现了一个简单的投票应用程序。**相比于使用互斥锁和条件变量，使用 channel 更加简洁和易于理解。**

##### 投票程序 6

```go
func main() {
	rand.Seed(time.Now().UnixNano())

	count := 0
	ch := make(chan bool)
	for i := 0; i < 10; i++ {
		go func() {
			ch <- requestVote()
		}()
	}
	for i := 0; i < 10; i++ {
		v := <-ch
		if v {
			count += 1
		}
	}
	if count >= 5 {
		println("received 5+ votes!")
	} else {
		println("lost")
	}
}

func requestVote() bool {
	time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)
	return rand.Int()%2 == 0
}
```

在 main 函数中，首先使用 rand.Seed 函数初始化随机数生成器。然后，定义了变量 count，表示收到的赞成票数。使用 make 函数创建了一个 bool 类型的 channel ch。

在第一个 for 循环中，使用 go func() 启动了 10 个 goroutine，每个 goroutine 执行 requestVote() 函数请求一次投票，并将投票结果发送到 channel ch 中。

在第二个 for 循环中，使用 <-ch 语句从 channel ch 中接收投票结果，并将结果存储到变量 v 中。如果 v 为 true，则将 count 变量加 1；否则，不做任何操作。

最后，根据 count 的值，输出相应的结果。

和代码 5 的不同之处在于第一个代码示例中，使用了一个额外的变量 finished 来记录已经处理完的请求个数，同时在 for 循环的条件判断中增加了一个条件 count < 5，表示只有收到 5 个以上的赞成票才会停止循环，并输出 "received 5+ votes!" 的结果。

而第二个代码示例中，只是简单地使用一个 for 循环来等待所有的请求处理完毕，然后再根据赞成票的数量输出相应的结果。

因此，第一个代码示例中的循环条件更加复杂，需要同时满足收到 5 个以上的赞成票并且所有的请求都已经处理完毕才会停止。而第二个代码示例中的循环条件更加简单，只需要等待所有的请求处理完毕即可。

在代码 5和代码 6 中，*都使用了无缓冲的 channel ch 来协调多个 goroutine 之间的同步和通信。*

具体来说，每个 goroutine 执行 requestVote() 函数请求一次投票，并将投票结果发送到 channel ch 中。在主 goroutine 中，使用 <-ch 语句从 channel ch 中接收投票结果，并将结果存储到变量 v 中。

在代码 1 中，使用一个额外的变量 finished 来记录已经处理完的请求个数，同时在 for 循环的条件判断中增加了一个条件 count < 5，表示只有收到 5 个以上的赞成票才会停止循环，并输出 "received 5+ votes!" 的结果。这样做的目的是为了避免无限等待，当已经收到了足够的赞成票或者所有的请求都已经处理完毕时，就可以停止循环并输出相应的结果。

而在代码 2 中，只是简单地使用一个 for 循环来等待所有的请求处理完毕，然后再根据赞成票的数量输出相应的结果。这样做的目的是为了简化代码逻辑，不需要额外的变量来记录已经处理完的请求个数，只需要等待所有的请求处理完毕即可。

总的来说，无缓冲的 channel ch 可以用于协调多个 goroutine 之间的同步和通信，通过向 channel 发送和接收数据来实现 goroutine 之间的交互。在这两个代码示例中，使用 channel ch 来实现多个 goroutine 之间的投票和结果统计，避免了使用互斥锁和条件变量所带来的锁竞争和死锁问题。

### 爬虫

##### 1. Serial crawler version

```
type Fetcher interface {
	// Fetch returns a slice of URLs found on the page.
	Fetch(url string) (urls []string, err error)
}

func Serial(url string, fetcher Fetcher, fetched map[string]bool) {
	if fetched[url] {
		return
	}
	fetched[url] = true
	urls, err := fetcher.Fetch(url)
	if err != nil {
		return
	}
	for _, u := range urls {
		Serial(u, fetcher, fetched)
	}
	return
}
```

这段代码实现了一个简单的串行爬虫，从给定的 URL 开始，依次爬取该页面中包含的所有链接。具体来说，该函数接受三个参数：

- url：要爬取的起始 URL。
- fetcher：用于获取页面内容和链接的 Fetcher 接口。
- fetched：已经访问过的 URL 列表。

在该函数中，首先检查当前要爬取的 URL 是否已经被访问过。如果已经访问过，则直接返回，否则将该 URL 标记为已经访问过。然后调用 fetcher.Fetch() 函数获取该 URL 对应页面的内容和链接，并将获取到的链接依次递归地传递给 Serial() 函数进行爬取。

**该函数的实现是递归的，将所有链接都依次爬取完毕后才会返回。因此，该函数的执行效率较低，不能充分利用并发性能。可以通过并发地爬取多个链接来提高爬虫的效率。**

总的来说，该函数实现了一个简单的串行爬虫，可以用于对单个网站进行爬取，但不适用于对大规模网站进行爬取。

##### 2. Concurrent crawler with shared state and Mutex version

```go
type fetchState struct {
	mu      sync.Mutex      // 互斥锁
	fetched map[string]bool // 已经访问过的 URL 列表
}

func ConcurrentMutex(url string, fetcher Fetcher, f *fetchState) {
	// 使用互斥锁保证多个 goroutine 对 f.fetched 的访问是串行的
	f.mu.Lock()
	already := f.fetched[url]
	f.fetched[url] = true
	f.mu.Unlock()

	// 如果该 URL 已经被访问过，则直接返回
	if already {
		return
	}

	// 调用 fetcher.Fetch() 函数获取该 URL 对应页面的内容和链接
	urls, err := fetcher.Fetch(url)
	if err != nil {
		return
	}

	// 使用 WaitGroup 维护计数器，确保所有 goroutine 都完成了对当前 URL 的爬取后再返回
	var done sync.WaitGroup
	for _, u := range urls {
		done.Add(1)
		// 使用 goroutine 实现并发爬取
		go func(u string) {
			defer done.Done()
			// 递归调用 ConcurrentMutex() 函数进行爬取
			ConcurrentMutex(u, fetcher, f)
		}(u)
	}
	done.Wait()
	return
}
```

这段代码实现了一个带有互斥锁的并发爬虫，*通过使用互斥锁来保证多个 goroutine 之间对同一个 URL 的爬取是串行的，避免了数据竞争和并发问题。*

该函数接受三个参数：

- url：要爬取的起始 URL。
- fetcher：用于获取页面内容和链接的 Fetcher 接口。
- f：包含互斥锁和已经访问过的 URL 列表的状态结构体。

在该函数中，首先使用互斥锁 f.mu.Lock() 来保证多个 goroutine 之间对 f.fetched 的访问是串行的，然后检查当前要爬取的 URL 是否已经被访问过，如果已经访问过，则直接返回，否则将该 URL 标记为已经访问过并释放互斥锁 f.mu.Unlock()。

然后调用 fetcher.Fetch() 函数获取该 URL 对应页面的内容和链接，并将获取到的链接依次递归地传递给 ConcurrentMutex() 函数进行爬取。在递归调用 ConcurrentMutex() 函数之前，使用 done.Add(1) 和 done.Done() 来维护一个计数器，确保所有 goroutine 都完成了对当前 URL 的爬取后再返回。

该函数使用了 goroutine 来实现并发爬取，每个 goroutine 都是独立的，可以并发地访问不同的 URL，提高了爬虫的效率。同时，通过使用互斥锁来保证对已经访问过的 URL 的访问是串行的，避免了数据竞争和并发问题，保证了程序的正确性。

总的来说，该函数实现了一个带有互斥锁的并发爬虫，可以用于对单个网站进行爬取，但不适用于对大规模网站进行爬取。



##### 3. Concurrent crawler with channels version

```go
// worker 函数用于获取指定 URL 的页面内容和链接，并将获取到的链接写入到一个 channel 中。
func worker(url string, ch chan []string, fetcher Fetcher) {
	// 调用 fetcher.Fetch() 函数获取指定 URL 的页面内容和链接
	urls, err := fetcher.Fetch(url)
	if err != nil {
		// 如果获取页面失败，则向 channel 中写入一个空字符串的切片
		ch <- []string{}
	} else {
		// 将获取到的链接写入到 channel 中
		ch <- urls
	}
}

// coordinator 函数作为协调者，从 channel 中读取链接，将尚未爬取过的链接分配给 worker 进行爬取，并将获取到的链接写入到 channel 中。
func coordinator(ch chan []string, fetcher Fetcher) {
	// 初始化计数器 n 和已经爬取过的链接列表 fetched
	n := 1
	fetched := make(map[string]bool)
	for urls := range ch {
		// 遍历从 channel 中读取到的链接列表
		for _, u := range urls {
			if fetched[u] == false {
				// 如果该链接尚未被爬取过，则将其标记为已经爬取过，并创建一个新的 worker goroutine 来进行爬取
				fetched[u] = true
				n += 1
				go worker(u, ch, fetcher)
			}
		}
		// 当所有链接都被爬取过后，计数器 n 减 1
		n -= 1
		// 当计数器 n 变为 0 时，终止函数
		if n == 0 {
			break
		}
	}
}

// ConcurrentChannel 函数作为入口函数，为起始 URL 创建一个 channel，并将该 URL 写入到 channel 中，然后调用协调者函数来分配任务并协调多个 worker 进行并发爬取。
func ConcurrentChannel(url string, fetcher Fetcher) {
	// 创建一个 channel
	ch := make(chan []string)
	// 在一个新的 goroutine 中将起始 URL 写入到 channel 中
	go func() {
		ch <- []string{url}
	}()
	// 调用协调者函数来分配任务并协调多个 worker 进行并发爬取
	coordinator(ch, fetcher)
}
```

这段代码实现了一个利用 channels 实现的并发爬虫，通过使用 channels 来协调多个 goroutine 之间的通信，实现了高效的并发爬取。

代码中定义了三个函数：

- worker：用于获取指定 URL 的页面内容和链接，并将获取到的链接写入到一个 channel 中。
- coordinator：作为协调者，从 channel 中读取链接，将尚未爬取过的链接分配给 worker 进行爬取，并将获取到的链接写入到 channel 中。当所有链接都被爬取过后，该函数终止。
- ConcurrentChannel：作为入口函数，为起始 URL 创建一个 channel，并将该 URL 写入到 channel 中，然后调用协调者函数来分配任务并协调多个 worker 进行并发爬取。

在 worker 函数中，首先调用 fetcher.Fetch() 函数获取指定 URL 的页面内容和链接，然后将获取到的链接写入到一个 channel 中。如果获取页面失败，则向 channel 中写入一个空字符串的切片。

在 coordinator 函数中，使用一个 map 来记录已经爬取过的链接，对于从 channel 中读取到的每个链接，判断它是否已经被爬取过。如果没有被爬取过，则将其标记为已经爬取过，并创建一个新的 worker goroutine 来进行爬取。然后将计数器 n 加 1，表示有一个新链接需要被爬取。当所有链接都被爬取过后，计数器 n 减 1，当计数器 n 变为 0 时，终止函数。

在 ConcurrentChannel 函数中，首先创建一个 channel，然后在一个新的 goroutine 中将起始 URL 写入到 channel 中。然后调用协调者函数来分配任务并协调多个 worker 进行并发爬取。

通过使用 channels 来协调多个 goroutine 之间的通信，可以避免使用互斥锁时可能出现的死锁和饥饿等问题，提高了程序的并发性和稳定性。该并发爬虫的实现相对简单，代码量也比较少，易于理解和修改。

### RPC

```go
package main

import (
	"fmt"
	"log"
	"net"
	"net/rpc"
	"sync"
)

//
// Common RPC request/reply definitions
//

const (
	OK       = "OK"
	ErrNoKey = "ErrNoKey"
)

// 错误类型
type Err string

// Put 请求参数
type PutArgs struct {
	Key   string
	Value string
}

// Put 响应参数
type PutReply struct {
	Err Err
}

// Get 请求参数
type GetArgs struct {
	Key string
}

// Get 响应参数
type GetReply struct {
	Err   Err
	Value string
}

//
// Client
//

// 连接 RPC 服务器
func connect() *rpc.Client {
	client, err := rpc.Dial("tcp", ":1234")
	if err != nil {
		log.Fatal("dialing:", err)
	}
	return client
}

// 获取键对应的值
func get(key string) string {
	client := connect()
	args := GetArgs{"subject"}
	reply := GetReply{}
	err := client.Call("KV.Get", &args, &reply) // 调用 KV.Get 方法
	if err != nil {
		log.Fatal("error:", err)
	}
	client.Close()
	return reply.Value
}

// 插入新的键值对
func put(key string, val string) {
	client := connect()
	args := PutArgs{"subject", "6.824"}
	reply := PutReply{}
	err := client.Call("KV.Put", &args, &reply) // 调用 KV.Put 方法
	if err != nil {
		log.Fatal("error:", err)
	}
	client.Close()
}

//
// Server
//

// 键值存储结构体
type KV struct {
	mu   sync.Mutex
	data map[string]string
}

// 启动 RPC 服务器
func server() {
	kv := new(KV)
	kv.data = map[string]string{}
	rpcs := rpc.NewServer()
	rpcs.Register(kv)
	l, e := net.Listen("tcp", ":1234") // 监听网络端口
	if e != nil {
		log.Fatal("listen error:", e)
	}
	go func() {
		for {
			conn, err := l.Accept() // 接收客户端连接
			if err == nil {
				go rpcs.ServeConn(conn) // 处理客户端请求
			} else {
				break
			}
		}
		l.Close()
	}()
}

// Get 方法的实现
func (kv *KV) Get(args *GetArgs, reply *GetReply) error {
	kv.mu.Lock() // 加锁
	defer kv.mu.Unlock() // 解锁

	val, ok := kv.data[args.Key] // 在数据存储中查找指定键对应的值
	if ok {
		reply.Err = OK
		reply.Value = val
	} else {
		reply.Err = ErrNoKey
		reply.Value = ""
	}
	return nil
}

// Put 方法的实现
func (kv *KV) Put(args *PutArgs, reply *PutReply) error {
	kv.mu.Lock() // 加锁
	defer kv.mu.Unlock() // 解锁

	kv.data[args.Key] = args.Value // 插入新的键值对
	reply.Err = OK
	return nil
}

//
// main
//

func main() {
	server() // 启动服务器

	put("subject", "6.824") // 插入新的键值对
	fmt.Printf("Put(subject, 6.824) done\n")

	fmt.Printf("get(subject) -> %s\n", get("subject")) // 获取键对应的值
}
```

这段代码实现了一个基于 RPC 的简单的键值存储系统。其主要包含三个部分：

1. Common RPC request/reply definitions：定义了客户端和服务器端之间的请求和响应的数据类型。
2. Client：实现了客户端的连接和数据读写的功能，包括连接到服务器、获取键值对等。
3. Server：实现了服务器端的功能，包括监听网络端口、接收客户端请求、处理请求并返回响应等。

具体来说，当客户端需要获取某个键对应的值时，会通过 RPC 调用发送一个 GetArgs 消息给服务器端，服务器端接收到消息后会在存储中查找相应的键值对，然后返回一个 GetReply 消息给客户端，其中包含了查找到的值。

当客户端需要插入一个新的键值对时，会通过 RPC 调用发送一个 PutArgs 消息给服务器端，服务器端接收到消息后会更新存储，并返回一个 PutReply 消息给客户端，其中包含了操作结果。

在 main 函数中，先启动服务器端，然后通过客户端依次插入和获取键值对，最后输出获取到的值。

该代码实现了一个简单的分布式存储系统，通过 RPC 通信，实现了客户端和服务器端之间的数据交互，可以用于学习分布式系统的基本概念和实现原理。



1. dial 函数

   在英文中，`dial` 的意思是“拨号”，通常用于描述建立电话或网络连接。在计算机领域中，`dial` 通常指建立网络连接的过程，比如使用 `net.Dial` 函数建立网络连接。

   `dial` 是 Go 语言中的一个函数，用于建立网络连接。在这个键值存储系统的代码中，`rpc.Dial` 函数用于建立客户端与服务器端之间的连接，其第一个参数是网络协议类型（比如 tcp、udp 等），第二个参数是服务器端的地址和端口号，返回一个 `rpc.Client` 类型的对象，表示客户端的连接。如果连接失败，则会返回一个非 `nil` 的错误对象。在这个键值存储系统的代码中，如果连接失败，程序会直接终止并输出错误信息。

## 新知识

### sync.Cond

#### sync.Cond 可以用来干什么？ 

Golang 的 sync 包中的 Cond 实现了一种**条件变量**，可以使用多个 Reader 等待公共资源。

每个 Cond 都会关联一个 Lock ,当修改条件或者调用 Wait 方法，必须加锁，保护 Condition。 有点类似 Java 中的 Wait 和 NotifyAll。

sync.Cond 条件变量是用来协调想要共享资源的那些 goroutine, 当共享资源的状态发生变化时，可以被用来通知被互斥锁阻塞的 gorountine。

#### 与 Sync.Mutex 的区别 

sync.Cond 基于互斥锁，和互斥锁有什么区别？

sync.Mutex 通常用来**保护临界区和共享资源**，条件变量 sync.Cond 用来**协调想要访问的共享资**源。

#### sync.Cond 使用场景 

有一个协程正在接收数据，其他协程必须等待这个协程接收完数据，才能读取到正确的数据。

上述情形下，如果单纯的使用 channel 或者互斥锁，只能有一个协程可以等待，并读取到数据，没办法通知其他协程也读取数据。

这个时候怎么办？

- 可以用一个全局变量标识第一个协程是否接收数据完毕，剩下的协程反复检查该变量的值，直到读取到数据。
- 也可创建多个 channel, 每个协程阻塞在一个 Channel 上，由接收数据的协程在数据接收完毕后，挨个通知。

然后 Go 中其实内置来一个 sync.Cond 来解决这个问题。

#### sync.Cond 

```
// Each Cond has an associated Locker L (often a *Mutex or *RWMutex),
// which must be held when changing the condition and
// when calling the Wait method.
//
// A Cond must not be copied after first use.
type Cond struct {
        noCopy noCopy

        // L is held while observing or changing the condition
        L Locker

        notify  notifyList
        checker copyChecker
}
```

可以看到每个 Cond 都会关联一个 锁 L (互斥锁 Mutex, 或者读写锁 * RMMutex), 当修改条件或者使用 Wait 的时候必须要加锁。

sync.Cond 类型包含了一个私有的互斥锁（sync.Mutex 类型），以及一个私有的等待队列。在使用 sync.Cond 类型时，通常需要先获取互斥锁，然后使用 sync.Cond 类型的 Wait、Signal 和 Broadcast 函数来实现条件变量的等待和通知。

sync.Cond 类型提供了以下几个函数：

- `Wait()`：等待条件变量被通知。此函数会释放互斥锁，并在等待队列中等待通知。一旦收到通知，该函数会重新获取互斥锁，并返回。
- `Signal()`：通知一个正在等待条件变量的 goroutine。此函数会随机选择一个等待队列中的 goroutine，并通知它。
- `Broadcast()`：通知所有正在等待条件变量的 goroutine。此函数会通知等待队列中的所有 goroutine。

使用 sync.Cond 类型时，需要注意以下几点：

- 必须先获取互斥锁才能使用条件变量。
- 必须在互斥锁的保护下使用条件变量。
- 必须在调用 Wait、Signal 或 Broadcast 函数前，已经获取了互斥锁。
- 在调用 Signal 或 Broadcast 函数后，被通知的 goroutine 不会立即执行，而是等待获取互斥锁后再执行。
- 在调用 Wait 函数时，会自动释放互斥锁，并在等待队列中等待通知，一旦收到通知，会自动重新获取互斥锁并继续执行。

#### sync.Cond 有哪些方法 

##### NewCond 创建实例 

```
func NewCond(l Locker) *Cond
```

NewCond 创建实例需要关联一个锁。

具体实例：

```
cadence := sync.NewCond(&sync.Mutex{})
```

##### Broadcast 广播唤醒所有 

```
// Broadcast wakes all goroutines waiting on c.
//
// It is allowed but not required for the caller to hold c.L
// during the call.
func (c *Cond) Broadcast()

```

Broadcast 唤醒所有等待条件变量 c 的 goroutine，无需锁保护。

具体实例：

```
go func() {
   for range time.Tick(1 * time.Millisecond) {
      cadence.Broadcast()
   }
}()
```

##### Signal 唤醒一个协程 

```
// Signal wakes one goroutine waiting on c, if there is any.
//
// It is allowed but not required for the caller to hold c.L
// during the call.
func (c *Cond) Signal()
```

Signal 只唤醒任意1个等待条件变量 c 的 goroutine，无需锁保护。 有点类似 Java 中的 Notify

##### Wait 等待 

```
// Wait atomically unlocks c.L and suspends execution
// of the calling goroutine. After later resuming execution,
// Wait locks c.L before returning. Unlike in other systems,
// Wait cannot return unless awoken by Broadcast or Signal.
//
// Because c.L is not locked when Wait first resumes, the caller
// typically cannot assume that the condition is true when
// Wait returns. Instead, the caller should Wait in a loop:
//
//    c.L.Lock()
//    for !condition() {
//        c.Wait()
//    }
//    ... make use of condition ...
//    c.L.Unlock()
//
func (c *Cond) Wait()

```

调用 Wait 会自动释放锁 c.L，并挂起调用者所在的 goroutine，因此当前协程会阻塞在 Wait 方法调用的地方。如果其他协程调用了 Signal 或 Broadcast 唤醒了该协程，Wait 方法结束阻塞时，并重新给 c.L 加锁，并且继续执行 Wait 后面的代码

代码示例：

```
c.L.Lock()
for !condition() {
    c.Wait()
}
... make use of condition ...
c.L.Unlock()
```



### RPC

RPC（Remote Procedure Call）远程过程调用，是一种进程间通信的技术，它使得应用程序能够像调用本地函数一样调用远程计算机上的函数，从而隐藏了计算机网络的细节，使得分布式系统的开发更加容易。

在 RPC 中，客户端应用程序通过调用一个本地的 stub 函数来代替远程的函数调用，stub 函数将参数打包成网络消息格式发送给远程计算机，远程计算机接收到消息后，将消息解包并调用对应的函数，将结果打包成网络消息格式发送给客户端，客户端接收到消息后，将结果解包并返回给调用者。整个过程就像是本地函数的调用一样简单，但实际上涉及了复杂的网络通信和数据传输过程。

RPC 可以通过各种协议和技术来实现，如 XML-RPC、SOAP、REST 等。RPC 技术广泛应用于分布式系统、云计算、微服务等领域，它使得分布式系统的开发更加容易，提高了系统的可扩展性、可维护性和可靠性。



在 RPC 中，`at-least-once` 和 `at-most-once` 是两种常见的调用语义，用于描述远程方法调用的重试策略。

`at-least-once` 调用语义表示调用者会尝试多次调用远程方法，直到收到一个可靠的响应为止。这种调用语义可以保证调用者的请求一定会被处理，但可能会导致重复执行请求，从而产生一些副作用，比如重复插入数据库记录等。为了避免这种情况发生，通常需要在远程方法中添加幂等性措施，保证多次执行同一个请求的结果是一致的。

`at-most-once` 调用语义表示调用者只会尝试调用远程方法一次，如果收到响应，则认为请求已经被处理，否则认为请求失败。这种调用语义可以保证请求不会被重复执行，但也可能会导致请求丢失。为了避免这种情况发生，通常需要在远程方法中添加重试措施，比如使用消息队列等方式来保证请求的可靠性。

在实际应用中，通常需要根据具体的场景来选择适当的调用语义，权衡请求的可靠性和副作用的影响。比如，对于读操作，通常可以使用 `at-most-once` 调用语义，因为读操作不会产生副作用；对于写操作，通常需要使用 `at-least-once` 调用语义，并在远程方法中添加幂等性措施，以保证请求的正确执行。